{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "target_schema = '<target schema>'\r\n",
        "storage_account = '<storage account>'\r\n",
        "container = '<container>'\r\n",
        "servername = '<server>'\r\n",
        "dbname = '<database>'\r\n",
        "entity_concurrency = 4"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc\n",
        "import struct\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "sql_token = mssparkutils.credentials.getToken('DW')\n",
        "token_bytes = sql_token.encode(\"UTF-16-LE\")\n",
        "token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\n",
        "\n",
        "SQL_COPT_SS_ACCESS_TOKEN = 1256\n",
        "conn = pyodbc.connect( 'DRIVER={ODBC Driver 18 for SQL Server};'\n",
        "                       f'SERVER={servername};'\n",
        "                       f'DATABASE={dbname}', \\\n",
        "                       attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\n",
        "\n",
        "cursor = conn.execute(  'SELECT DISTINCT [EntityName]'\n",
        "                        'FROM [DataverseToSql].[BlobsToIngest]'\n",
        "                        'WHERE [LoadType] = 0 AND [Complete] = 0')\n",
        "\n",
        "def run_notebook(entity):\n",
        "    mssparkutils.notebook.run('$$PROCESS_ENTITY_NOTEBOOK_NAME$$', 7200, {\n",
        "        \"entity\": entity,\n",
        "        \"target_schema\": target_schema,\n",
        "        \"storage_account\": storage_account,\n",
        "        \"container\": container,\n",
        "        \"servername\": servername,\n",
        "        \"dbname\": dbname,\n",
        "        })\n",
        "\n",
        "with ThreadPoolExecutor(max_workers = entity_concurrency) as executor:\n",
        "    for result in executor.map(run_notebook, [row[0] for row in cursor]):\n",
        "        print(result)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "tags": []
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}